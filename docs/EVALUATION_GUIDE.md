# è¯„ä¼°ç³»ç»Ÿä½¿ç”¨æŒ‡å—

## ğŸ“– æ¦‚è¿°

æœ¬é¡¹ç›®å·²æ•´åˆäº† `anlp-fall2025-hw3` ç›®å½•ä¸‹çš„æµ‹è¯•æ•°æ®å’Œè¯„æµ‹æŒ‡æ ‡è®¡ç®—åŠŸèƒ½ã€‚ç°åœ¨ä½ å¯ä»¥ï¼š

1. ä½¿ç”¨ä¸åŒéš¾åº¦çš„æµ‹è¯•æ•°æ®ï¼ˆeasy/medium/hardï¼‰
2. æ‰¹é‡è¿è¡Œæ¸¸æˆè¿›è¡Œè¯„ä¼°
3. è®¡ç®—å¤šç§è¯„ä¼°æŒ‡æ ‡ï¼ˆèƒœç‡ã€æ£€æµ‹ç‡ã€è¯­è¨€è¿è´¯æ€§ç­‰ï¼‰

## ğŸ“ æ–‡ä»¶ç»“æ„

```
é¡¹ç›®æ ¹ç›®å½•/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ word_pairs.py          # è¯æ±‡å¯¹æ•°æ®åŠ è½½æ¨¡å—
â”œâ”€â”€ evaluation/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ metrics.py             # è¯„ä¼°æŒ‡æ ‡è®¡ç®—æ¨¡å—
â”œâ”€â”€ evaluate.py                # æ‰¹é‡è¯„ä¼°è„šæœ¬
â””â”€â”€ anlp-fall2025-hw3/         # åŸå§‹æµ‹è¯•æ•°æ®
    â””â”€â”€ data/
        â”œâ”€â”€ easy_keyword_pair.json
        â”œâ”€â”€ midium_keyword_pair.json
        â”œâ”€â”€ hard_keyword_pair.json
        â””â”€â”€ keyword_pair.json
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ä½¿ç”¨è¯„ä¼°è„šæœ¬

æœ€ç®€å•çš„ä½¿ç”¨æ–¹å¼æ˜¯è¿è¡Œ `evaluate.py` è„šæœ¬ï¼š

```bash
# è¿è¡Œ10å±€æ¸¸æˆï¼Œä½¿ç”¨æ‰€æœ‰éš¾åº¦çš„è¯æ±‡å¯¹
python evaluate.py --num-games 10 --difficulty all

# åªä½¿ç”¨ç®€å•éš¾åº¦çš„è¯æ±‡å¯¹
python evaluate.py --num-games 20 --difficulty easy

# è‡ªå®šä¹‰ç©å®¶å’Œå§åº•æ•°é‡
python evaluate.py --num-games 10 --num-players 8 --num-undercover 2

# å®‰é™æ¨¡å¼ï¼ˆä¸æ‰“å°è¯¦ç»†ä¿¡æ¯ï¼‰
python evaluate.py --num-games 10 --quiet

# ä¿å­˜ç»“æœåˆ°æŒ‡å®šæ–‡ä»¶
python evaluate.py --num-games 10 --output my_results.json
```

### 2. åœ¨ä»£ç ä¸­ä½¿ç”¨

#### åŠ è½½æµ‹è¯•æ•°æ®

```python
from data import load_word_pairs

# åŠ è½½æ‰€æœ‰éš¾åº¦çš„è¯æ±‡å¯¹
all_pairs = load_word_pairs(difficulty="all")

# åªåŠ è½½ç®€å•éš¾åº¦çš„
easy_pairs = load_word_pairs(difficulty="easy")

# åªåŠ è½½ä¸­ç­‰éš¾åº¦çš„
medium_pairs = load_word_pairs(difficulty="medium")

# åªåŠ è½½å›°éš¾éš¾åº¦çš„
hard_pairs = load_word_pairs(difficulty="hard")

# ä½¿ç”¨é»˜è®¤çš„ä¸­æ–‡è¯æ±‡å¯¹
default_pairs = load_word_pairs(difficulty="default")
```

#### è¿è¡Œå•å±€æ¸¸æˆå¹¶è¯„ä¼°

```python
from graph.workflow import create_undercover_workflow
from data import load_word_pairs
from evaluation import evaluate_game_result

# åŠ è½½è¯æ±‡å¯¹
word_pairs = load_word_pairs(difficulty="easy")

# åˆ›å»ºæ¸¸æˆçŠ¶æ€
initial_state = {
    "num_players": 6,
    "num_undercover": 1,
    "word_pairs": word_pairs,  # ä¼ é€’è¯æ±‡å¯¹
    # ... å…¶ä»–çŠ¶æ€
}

# è¿è¡Œæ¸¸æˆ
workflow = create_undercover_workflow()
app = workflow.compile()
final_state = None
for state in app.stream(initial_state):
    final_state = state

# è¯„ä¼°ç»“æœ
if final_state:
    final_state_dict = {}
    for node_name, node_state in final_state.items():
        if node_state:
            final_state_dict.update(node_state)
    
    metrics = evaluate_game_result(final_state_dict)
    print(f"å¹³æ°‘è·èƒœ: {metrics['civilian_won']}")
    print(f"æ£€æµ‹ç‡: {metrics['detection_rate']:.2%}")
    print(f"è¯­è¨€è¿è´¯æ€§: {metrics['linguistic_coherence']:.4f}")
```

#### æ‰¹é‡è¯„ä¼°

```python
from evaluate import run_evaluation

# è¿è¡Œæ‰¹é‡è¯„ä¼°
results = run_evaluation(
    num_games=10,
    num_players=6,
    num_undercover=1,
    difficulty="all",
    verbose=True
)

# æŸ¥çœ‹ç»“æœ
summary = results["summary"]
print(f"å¹³æ°‘èƒœç‡: {summary['civilian_win_rate']:.2%}")
print(f"å§åº•èƒœç‡: {summary['undercover_win_rate']:.2%}")
print(f"å¹³å‡æ£€æµ‹ç‡: {summary['avg_detection_rate']:.2%}")
```

## ğŸ“Š è¯„ä¼°æŒ‡æ ‡è¯´æ˜

### 1. èƒœç‡ (Win Rate)
- **å¹³æ°‘èƒœç‡**: å¹³æ°‘è·èƒœçš„æ¸¸æˆæ¯”ä¾‹
- **å§åº•èƒœç‡**: å§åº•è·èƒœçš„æ¸¸æˆæ¯”ä¾‹

### 2. æ£€æµ‹ç‡ (Detection Rate)
- å§åº•è¢«æ­£ç¡®è¯†åˆ«å¹¶æ·˜æ±°çš„æ¯”ä¾‹
- èŒƒå›´: 0.0 - 1.0

### 3. è¯­è¨€è¿è´¯æ€§ (Linguistic Coherence)
- ç©å®¶æè¿°ä¸å‚è€ƒæ–‡æœ¬ï¼ˆå¹³æ°‘è¯ï¼‰çš„ç›¸ä¼¼åº¦
- åŸºäºè¯æ±‡é‡å è®¡ç®—ï¼ˆå¯æ‰©å±•ä¸º BERTScoreï¼‰
- èŒƒå›´: 0.0 - 1.0

### 4. è¯´æœåŠ›åˆ†æ•° (Persuasion Score)
- ç©å®¶è¯è¯­çš„è¯´æœåŠ›è¯„åˆ†
- å½“å‰ä¸ºå ä½ç¬¦å®ç°ï¼Œå¯æ‰©å±•ä¸º GPT-4 è¯„åˆ†

### 5. å¿ƒç†ç†è®ºåˆ†æ•° (Theory of Mind)
- **1-Word**: é¢„æµ‹å…¶ä»–ç©å®¶çš„è¯
- **1-Identity**: é¢„æµ‹å…¶ä»–ç©å®¶çš„èº«ä»½
- **2-Word**: é¢„æµ‹å…¶ä»–ç©å®¶è®¤ä¸ºæˆ‘çš„è¯æ˜¯ä»€ä¹ˆ
- **2-Identity**: é¢„æµ‹å…¶ä»–ç©å®¶è®¤ä¸ºæˆ‘çš„èº«ä»½æ˜¯ä»€ä¹ˆ

## ğŸ”§ é«˜çº§ç”¨æ³•

### è‡ªå®šä¹‰è¯æ±‡å¯¹

```python
from graph.nodes import set_word_pairs

# è‡ªå®šä¹‰è¯æ±‡å¯¹
custom_pairs = [
    {"civilian": "Apple", "undercover": "Pear"},
    {"civilian": "Dog", "undercover": "Cat"},
]

# è®¾ç½®å…¨å±€è¯æ±‡å¯¹
set_word_pairs(custom_pairs)

# ç„¶åè¿è¡Œæ¸¸æˆï¼Œä¼šä½¿ç”¨è¿™äº›è¯æ±‡å¯¹
```

### ä½¿ç”¨ä¸åŒéš¾åº¦çš„æ•°æ®

```python
from data import get_word_pairs_by_difficulty

# è·å–æŒ‰éš¾åº¦åˆ†ç±»çš„è¯æ±‡å¯¹
pairs_by_difficulty = get_word_pairs_by_difficulty()

easy_pairs = pairs_by_difficulty["easy"]
medium_pairs = pairs_by_difficulty["medium"]
hard_pairs = pairs_by_difficulty["hard"]

print(f"ç®€å•: {len(easy_pairs)} å¯¹")
print(f"ä¸­ç­‰: {len(medium_pairs)} å¯¹")
print(f"å›°éš¾: {len(hard_pairs)} å¯¹")
```

### è®¡ç®—å•ä¸ªæŒ‡æ ‡

```python
from evaluation import (
    compute_win_rate,
    compute_detection_rate,
    compute_linguistic_coherence,
    compute_tom_scores
)

# è®¡ç®—èƒœç‡
game_results = [
    {"winner": "civilian", "players": [...]},
    {"winner": "undercover", "players": [...]},
]
civilian_win_rate = compute_win_rate(game_results, role="civilian")

# è®¡ç®—æ£€æµ‹ç‡
game_logs = [
    {"players": [...], "eliminated_players": [3], ...},
]
detection_rate = compute_detection_rate(game_logs, player_id=3)

# è®¡ç®—è¯­è¨€è¿è´¯æ€§
descriptions = ["A red fruit", "A sweet fruit", "Round and red"]
reference = "Apple"
coherence = compute_linguistic_coherence(descriptions, reference)
```

## ğŸ“ æ•°æ®æ ¼å¼

### è¯æ±‡å¯¹æ ¼å¼

æµ‹è¯•æ•°æ®ä¸­çš„è¯æ±‡å¯¹æ ¼å¼ä¸ºï¼š
```json
[
    ["Civilian Word", "Undercover Word"],
    ["Apple", "Pear"],
    ...
]
```

åŠ è½½åè½¬æ¢ä¸ºé¡¹ç›®æ ¼å¼ï¼š
```python
[
    {"civilian": "Apple", "undercover": "Pear"},
    ...
]
```

### æ¸¸æˆç»“æœæ ¼å¼

æ¸¸æˆç»“æœåŒ…å«ä»¥ä¸‹å­—æ®µï¼š
```python
{
    "winner": "civilian" | "undercover",
    "round": 3,
    "players": [...],
    "elimination_history": [...],
    "current_descriptions": [...],
    "current_votes": [...],
    ...
}
```

## âš™ï¸ é…ç½®é€‰é¡¹

### evaluate.py å‚æ•°

- `--num-games`: æ¸¸æˆå±€æ•°ï¼ˆé»˜è®¤: 10ï¼‰
- `--num-players`: ç©å®¶æ•°é‡ï¼ˆé»˜è®¤: 6ï¼‰
- `--num-undercover`: å§åº•æ•°é‡ï¼ˆé»˜è®¤: 1ï¼‰
- `--difficulty`: éš¾åº¦çº§åˆ«ï¼ˆeasy/medium/hard/all/defaultï¼Œé»˜è®¤: allï¼‰
- `--output`: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤: evaluation_results.jsonï¼‰
- `--quiet`: å®‰é™æ¨¡å¼ï¼Œä¸æ‰“å°è¯¦ç»†ä¿¡æ¯

## ğŸ¯ ä½¿ç”¨åœºæ™¯

### åœºæ™¯1: æ¨¡å‹æ€§èƒ½è¯„ä¼°
```bash
# è¯„ä¼°æ¨¡å‹åœ¨ä¸åŒéš¾åº¦ä¸‹çš„è¡¨ç°
python evaluate.py --num-games 50 --difficulty easy
python evaluate.py --num-games 50 --difficulty medium
python evaluate.py --num-games 50 --difficulty hard
```

### åœºæ™¯2: å‚æ•°è°ƒä¼˜
```python
# è¿è¡Œå¤šç»„å®éªŒï¼Œæ¯”è¾ƒä¸åŒå‚æ•°è®¾ç½®
for temperature in [0.5, 0.7, 0.9]:
    # è®¾ç½®æ¨¡å‹å‚æ•°
    # è¿è¡Œè¯„ä¼°
    results = run_evaluation(num_games=20, ...)
    # æ¯”è¾ƒç»“æœ
```

### åœºæ™¯3: å¤šæ¨¡å‹å¯¹æ¯”
```python
# ä¸ºä¸åŒç©å®¶åˆ†é…ä¸åŒæ¨¡å‹
# è¿è¡Œè¯„ä¼°ï¼Œæ¯”è¾ƒå„æ¨¡å‹è¡¨ç°
```

## ğŸ“Œ æ³¨æ„äº‹é¡¹

1. **æ•°æ®è·¯å¾„**: é»˜è®¤ä» `anlp-fall2025-hw3/data/` ç›®å½•åŠ è½½æ•°æ®
2. **API é™åˆ¶**: æ‰¹é‡è¿è¡Œæ—¶æ³¨æ„ API è°ƒç”¨é™åˆ¶
3. **æˆæœ¬æ§åˆ¶**: å¤§é‡æ¸¸æˆä¼šäº§ç”Ÿ API è°ƒç”¨è´¹ç”¨
4. **ç»“æœä¿å­˜**: é»˜è®¤åªä¿å­˜æ‘˜è¦ï¼Œå®Œæ•´ç»“æœå¯èƒ½å¾ˆå¤§

## ğŸ”® æœªæ¥æ‰©å±•

- [ ] é›†æˆ BERTScore è¿›è¡Œæ›´å‡†ç¡®çš„è¯­è¨€è¿è´¯æ€§è®¡ç®—
- [ ] ä½¿ç”¨ GPT-4 è¿›è¡Œè¯´æœåŠ›è¯„åˆ†
- [ ] æ”¯æŒå¿ƒç†ç†è®ºï¼ˆToMï¼‰æ•°æ®çš„æ”¶é›†å’Œè¯„ä¼°
- [ ] å¯è§†åŒ–è¯„ä¼°ç»“æœ
- [ ] æ”¯æŒå¹¶è¡Œè¿è¡Œå¤šå±€æ¸¸æˆ

